{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Generation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stresses={\n",
    "        'T_1':80,\n",
    "        #'T_2':80,\n",
    "       # 'T_3':80,\n",
    "       # 'T_4':80,\n",
    "        #'T_5':80,\n",
    "       # 'T_6':80\n",
    "}\n",
    "columns=['stresses','magnetostriction','strain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(columns=columns)\n",
    "n_e=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_e):\n",
    "        stress=np.random.normal(80,20)\n",
    "        magnetostriction=np.random.normal(0.006,0.0001)\n",
    "        strain=np.random.normal(0.004,0.0001)\n",
    "        data.loc[i]=[stress,magnetostriction,strain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "##for test data\n",
    "for i in range(400):\n",
    "        stress=np.random.normal(80,20)\n",
    "        magnetostriction=np.random.normal(0.006,0.0001)\n",
    "        strain=np.random.normal(0.004,0.0001)\n",
    "        data.loc[i]=[stress,magnetostriction,strain]\n",
    "\n",
    "dataframe_test=pd.read_csv('test_data',index_col=False)\n",
    "dataframe_test.head()\n",
    "dataframe=pd.read_csv('test_data',index_col=False)\n",
    "X_test=dataframe_test[['stresses','magnetostriction','strain']]\n",
    "Y_test=dataframe_test[['stresses']]\n",
    "x_test=X_test.to_numpy()\n",
    "y_test=Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.read_csv('test_data',index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>stresses</th>\n",
       "      <th>magnetostriction</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>44.030513</td>\n",
       "      <td>0.006046</td>\n",
       "      <td>0.003848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70.611077</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>0.003927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.404324</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>0.003907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>81.506225</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.003896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>78.625517</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.003937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   stresses  magnetostriction    strain\n",
       "0           0  44.030513          0.006046  0.003848\n",
       "1           1  70.611077          0.005925  0.003927\n",
       "2           2  62.404324          0.005907  0.003907\n",
       "3           3  81.506225          0.005928  0.003896\n",
       "4           4  78.625517          0.005878  0.003937"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input=dataframe[['stresses','magnetostriction','strain']]\n",
    "#y_input=dataframe['stresses']\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_input\n",
    "#y=y_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stresses</th>\n",
       "      <th>magnetostriction</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.030513</td>\n",
       "      <td>0.006046</td>\n",
       "      <td>0.003848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.611077</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>0.003927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.404324</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>0.003907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.506225</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.003896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.625517</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.003937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>79.714180</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.003964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>85.637667</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.003805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>58.269149</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.003992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>57.640931</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>0.003996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>95.471235</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.003923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stresses  magnetostriction    strain\n",
       "0    44.030513          0.006046  0.003848\n",
       "1    70.611077          0.005925  0.003927\n",
       "2    62.404324          0.005907  0.003907\n",
       "3    81.506225          0.005928  0.003896\n",
       "4    78.625517          0.005878  0.003937\n",
       "..         ...               ...       ...\n",
       "995  79.714180          0.006043  0.003964\n",
       "996  85.637667          0.005986  0.003805\n",
       "997  58.269149          0.005901  0.003992\n",
       "998  57.640931          0.006058  0.003996\n",
       "999  95.471235          0.005935  0.003923\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = X_train.astype('float32')\n",
    "#x_test = X_test.astype('float32')\n",
    "#y_train=y_train.astype('float')\n",
    "#y_test=y_test.astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_input_x=X.to_numpy()###700X2\n",
    "#array_input_y=y_train.to_numpy()###700X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape\n",
    "#from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD THE MODEL\n",
    "\n",
    "# # ================= #############\n",
    "# # Encoder\n",
    "# # ================= ############\n",
    "\n",
    "latent_dim = 2 # Number of latent dim parameters\n",
    "\n",
    "input_encoder = Input(shape=3, name='encoder_input')\n",
    "x = Dense(32, activation='relu')(input_encoder)\n",
    "x = Dense(64 , activation='relu')(x)\n",
    "\n",
    "\n",
    "conv_shape = K.int_shape(x) #Shape of conv to be provided to decoder\n",
    "#Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 64)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Two outputs, for latent mean and log variance (std. dev.)\n",
    "#Use these to sample random variables in latent space to which inputs are mapped. \n",
    "z_mu = Dense(latent_dim, name='latent_mu')(x)   #Mean values of encoded input\n",
    "z_sigma = Dense(latent_dim, name='latent_sigma')(x)  #Std dev. (variance) of encoded input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPARAMETERIZATION TRICK\n",
    "# Define sampling function to sample from the distribution\n",
    "# Reparameterize sample based on the process defined by Gunderson and Huang\n",
    "# into the shape of: mu + sigma squared x eps\n",
    "#This is to allow gradient descent to allow for gradient estimation accurately. \n",
    "def sample_z(args):\n",
    "  z_mu, z_sigma = args\n",
    "  eps = K.random_normal(shape=(K.shape(z_mu)[0], K.int_shape(z_mu)[1]))\n",
    "  return z_mu + K.exp(z_sigma / 2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample vector from the latent distribution\n",
    "# z is the labda custom layer we are adding for gradient descent calculations\n",
    "  # using mu and variance (sigma)\n",
    "z = Lambda(sample_z, output_shape=(latent_dim, ), name='z')([z_mu, z_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 32)           128         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 64)           2112        ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " latent_mu (Dense)              (None, 2)            130         ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " latent_sigma (Dense)           (None, 2)            130         ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 2)            0           ['latent_mu[0][0]',              \n",
      "                                                                  'latent_sigma[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,500\n",
      "Trainable params: 2,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Z (lambda layer) will be the last layer in the encoder.\n",
    "# Define and summarize encoder model.\n",
    "encoder = Model(input_encoder, [z_mu, z_sigma, z], name='encoder')\n",
    "print(encoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 3)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "\n",
    "# decoder takes the latent vector as input\n",
    "decoder_input = Input(shape=(latent_dim, ), name='decoder_input')\n",
    "\n",
    "#we want our final utput to be same shape original input.\n",
    "x = Dense(3, activation='relu')(decoder_input)\n",
    "\n",
    "# Define and summarize decoder model\n",
    "decoder = Model(decoder_input, x, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "# apply the decoder to the latent sample \n",
    "z_decoded = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define custom loss\n",
    "#VAE is trained using two loss functions reconstruction loss and KL divergence\n",
    "#Let us add a class to define a custom layer with loss\n",
    "class CustomLayer(keras.layers.Layer):\n",
    "\n",
    "    def vae_loss(self, x, z_decoded):\n",
    "        x = K.flatten(x)\n",
    "        z_decoded = K.flatten(z_decoded)\n",
    "        \n",
    "        # Reconstruction loss (as we used sigmoid activation we can use binarycrossentropy)\n",
    "        recon_loss = keras.metrics.mse(x, z_decoded)\n",
    "        \n",
    "        # KL divergence\n",
    "        kl_loss = -5e-4 * K.mean(1 + z_sigma - K.square(z_mu) - K.exp(z_sigma), axis=-1)\n",
    "        return K.mean(recon_loss + kl_loss)\n",
    "\n",
    "    # add custom loss to the class\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        z_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, z_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output custom_layer_10 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_layer_10.\n",
      "Model: \"vae\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 32)           128         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 64)           2112        ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " latent_mu (Dense)              (None, 2)            130         ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " latent_sigma (Dense)           (None, 2)            130         ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 2)            0           ['latent_mu[0][0]',              \n",
      "                                                                  'latent_sigma[0][0]']           \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 3)            9           ['z[0][0]']                      \n",
      "                                                                                                  \n",
      " custom_layer_10 (CustomLayer)  (None, 3)            0           ['encoder_input[0][0]',          \n",
      "                                                                  'decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,509\n",
      "Trainable params: 2,509\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# apply the custom loss to the input images and the decoded latent distribution sample\n",
    "y = CustomLayer()([input_encoder, z_decoded])\n",
    "# y is basically the original image after encoding input img to mu, sigma, z\n",
    "# and decoding sampled z values.\n",
    "#This will be used as output for vae\n",
    "\n",
    "# =================\n",
    "# VAE \n",
    "# =================\n",
    "vae = Model(input_encoder, y, name='vae')\n",
    "\n",
    "# Compile VAE\n",
    "vae.compile(optimizer='adam', loss=None)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_decoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 3.1782 - val_loss: 3.3517\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 3.1509 - val_loss: 3.3235\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 3.1245 - val_loss: 3.2961\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 3.0984 - val_loss: 3.2685\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 3.0728 - val_loss: 3.2415\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 3.0472 - val_loss: 3.2150\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 3.0226 - val_loss: 3.1895\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 2.9985 - val_loss: 3.1640\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 2.9746 - val_loss: 3.1389\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 2.9510 - val_loss: 3.1140\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 2.9279 - val_loss: 3.0895\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 2.9051 - val_loss: 3.0660\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 2.8837 - val_loss: 3.0427\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 2.8615 - val_loss: 3.0206\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 2.8401 - val_loss: 2.9970\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 2.8187 - val_loss: 2.9758\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 2.7978 - val_loss: 2.9531\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 2.7780 - val_loss: 2.9324\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 2.7577 - val_loss: 2.9112\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 2.7376 - val_loss: 2.8916\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 2.7180 - val_loss: 2.8698\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 2.6995 - val_loss: 2.8502\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 2.6806 - val_loss: 2.8313\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 2.6635 - val_loss: 2.8108\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 2.6449 - val_loss: 2.7914\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 2.6257 - val_loss: 2.7727\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 2.6080 - val_loss: 2.7544\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 2.5910 - val_loss: 2.7364\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 2.5741 - val_loss: 2.7185\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 2.5575 - val_loss: 2.7022\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 2.5408 - val_loss: 2.6831\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 2.5247 - val_loss: 2.6657\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 2.5081 - val_loss: 2.6485\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 2.4925 - val_loss: 2.6325\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 2.4772 - val_loss: 2.6167\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 2.4616 - val_loss: 2.5994\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 2.4467 - val_loss: 2.5844\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 2.4312 - val_loss: 2.5680\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 2.4168 - val_loss: 2.5527\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 2.4021 - val_loss: 2.5370\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 2.3873 - val_loss: 2.5220\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 2.3735 - val_loss: 2.5076\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 2.3592 - val_loss: 2.4924\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 2.3454 - val_loss: 2.4776\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 2.3317 - val_loss: 2.4634\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 2.3191 - val_loss: 2.4493\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 2.3054 - val_loss: 2.4347\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 2.2917 - val_loss: 2.4211\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 2.2785 - val_loss: 2.4076\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 2.2662 - val_loss: 2.3949\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 2.2532 - val_loss: 2.3805\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 2.2402 - val_loss: 2.3671\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 2.2280 - val_loss: 2.3539\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 2.2156 - val_loss: 2.3411\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 2.2031 - val_loss: 2.3294\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 2.1913 - val_loss: 2.3152\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 2.1797 - val_loss: 2.3034\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 2.1677 - val_loss: 2.2907\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 2.1561 - val_loss: 2.2790\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 2.1447 - val_loss: 2.2660\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 2.1332 - val_loss: 2.2539\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 2.1222 - val_loss: 2.2423\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 2.1106 - val_loss: 2.2301\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 2.0992 - val_loss: 2.2188\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 2.0884 - val_loss: 2.2068\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 2.0773 - val_loss: 2.1955\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 2.0665 - val_loss: 2.1838\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 2.0557 - val_loss: 2.1726\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 2.0453 - val_loss: 2.1613\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 2.0348 - val_loss: 2.1500\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 2.0241 - val_loss: 2.1390\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 2.0134 - val_loss: 2.1283\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 2.0037 - val_loss: 2.1181\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 1.9931 - val_loss: 2.1064\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 1.9830 - val_loss: 2.0959\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 1.9727 - val_loss: 2.0849\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 1.9629 - val_loss: 2.0747\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 1.9528 - val_loss: 2.0639\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 1.9427 - val_loss: 2.0534\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 1.9332 - val_loss: 2.0431\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 1.9235 - val_loss: 2.0331\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 1.9137 - val_loss: 2.0232\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 1.9046 - val_loss: 2.0123\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 1.8946 - val_loss: 2.0027\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 1.8848 - val_loss: 1.9926\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 1.8754 - val_loss: 1.9824\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 1.8664 - val_loss: 1.9725\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 1.8572 - val_loss: 1.9635\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 1.8478 - val_loss: 1.9526\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 1.8385 - val_loss: 1.9434\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 64us/sample - loss: 1.8290 - val_loss: 1.9334\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 1.8209 - val_loss: 1.9241\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.8110 - val_loss: 1.9146\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 1.8020 - val_loss: 1.9046\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 1.7933 - val_loss: 1.8951\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 1.7840 - val_loss: 1.8853\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 65us/sample - loss: 1.7753 - val_loss: 1.8762\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 1.7669 - val_loss: 1.8670\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 1.7575 - val_loss: 1.8577\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 1.7490 - val_loss: 1.8485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2731312bfa0>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train autoencoder\n",
    "vae.fit(array_input_x, None, epochs = 100, batch_size = 32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================\n",
    "# Visualize results\n",
    "# =================\n",
    "#Visualize inputs mapped to the Latent space\n",
    "#Remember that we have encoded inputs to latent space dimension = 2. \n",
    "#Extract z_mu --> first parameter in the result of encoder prediction representing mean\n",
    "\n",
    "mu, _, _ = encoder.predict(x_test)\n",
    "#Plot dim1 and dim2 for mu\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(mu[:, 0], mu[:, 1], c=y_test, cmap='brg')\n",
    "plt.xlabel('dim 1')\n",
    "plt.ylabel('dim 2')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2731a9df070>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_vector = np.array([[-100,100]])\n",
    "decoded_example = decoder.predict(sample_vector)\n",
    "#decoded_example_reshaped = decoded_example.reshape(img_width, img_height)\n",
    "plt.imshow(decoded_example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be0c76a15e7db832c1cef9e000d0973fde535108692ea45e0855d7f2c98f1a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
